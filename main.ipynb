{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d1cb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "Training data: 1622 rows\n",
      "Test data: 104 rows\n",
      "Estimating brand metrics for test data...\n",
      "     year quarter     country       brand  predicted_power  quarter_num  \\\n",
      "0    2024    Qtr3  a19bbfeafb  cd46a210c6              NaN            3   \n",
      "1    2024    Qtr3  a19bbfeafb  b6a118bf97              NaN            3   \n",
      "2    2024    Qtr3  a19bbfeafb  53a67488ad              NaN            3   \n",
      "3    2024    Qtr3  a19bbfeafb  a0bc54a71d              NaN            3   \n",
      "4    2024    Qtr3  a19bbfeafb  85498197e2              NaN            3   \n",
      "..    ...     ...         ...         ...              ...          ...   \n",
      "99   2025    Qtr2  aa30935544  96ddb9088d              NaN            2   \n",
      "100  2025    Qtr2  aa30935544  6e31ce004a              NaN            2   \n",
      "101  2025    Qtr2  aa30935544  71e9e5f0c0              NaN            2   \n",
      "102  2025    Qtr2  aa30935544  a5f7e77993              NaN            2   \n",
      "103  2025    Qtr2  aa30935544  e7286b8344              NaN            2   \n",
      "\n",
      "     time_idx  is_test     meaning  difference    salience   premium  \n",
      "0       20243     True  140.885669  113.861601  160.464473  1.155262  \n",
      "1       20243     True  124.081871  104.935099  120.073537  1.054426  \n",
      "2       20243     True   86.743503   75.443914   79.131779  0.901318  \n",
      "3       20243     True  116.876435  119.421693   81.785540  1.128386  \n",
      "4       20243     True  149.631097  157.905315  125.040083  1.290739  \n",
      "..        ...      ...         ...         ...         ...       ...  \n",
      "99      20252     True  113.769778   85.835259  129.443763  0.975496  \n",
      "100     20252     True  120.813440  115.398571   98.808087  1.119105  \n",
      "101     20252     True   95.874613   90.411453   88.664452  0.943155  \n",
      "102     20252     True   87.232878  119.425302   90.665045  0.979184  \n",
      "103     20252     True   77.997992   93.479464   87.288678  0.971815  \n",
      "\n",
      "[104 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load data\n",
    "train_path = r'C:\\Users\\40108679\\OneDrive - Anheuser-Busch InBev\\Desktop\\Hackathon-2025\\lte_participants_data\\BG_Data_Hackathon_Train_masked.csv'\n",
    "test_path = r'C:\\Users\\40108679\\OneDrive - Anheuser-Busch InBev\\Desktop\\Hackathon-2025\\lte_participants_data\\BG_Data_Hackathon_Test_Predict_masked.csv'\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Standardize column names\n",
    "if 'Year' in df_test.columns:\n",
    "    df_test = df_test.rename(columns={'Year': 'year', 'Quarter': 'quarter', 'Country': 'country', \n",
    "                                     'Brand': 'brand', 'Predicted Power': 'predicted_power'})\n",
    "\n",
    "# Create quarter numeric values for time series ordering\n",
    "df_train['quarter_num'] = df_train['quarter'].str.replace('Qtr', '').astype(int)\n",
    "df_test['quarter_num'] = df_test['quarter'].str.replace('Qtr', '').astype(int)\n",
    "\n",
    "# Create time index for easier analysis\n",
    "df_train['time_idx'] = df_train['year']*10 + df_train['quarter_num']\n",
    "df_test['time_idx'] = df_test['year']*10 + df_test['quarter_num']\n",
    "\n",
    "# Create a combined DataFrame for easier sorting and mapping\n",
    "df_test['is_test'] = True\n",
    "df_train['is_test'] = False\n",
    "combined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "combined = combined.sort_values(['brand', 'country', 'year', 'quarter_num'])\n",
    "\n",
    "print(f\"Training data: {len(df_train)} rows\")\n",
    "print(f\"Test data: {len(df_test)} rows\")\n",
    "\n",
    "# Estimate brand metrics for test data using brand and country averages\n",
    "def estimate_brand_metrics():\n",
    "    print(\"Estimating brand metrics for test data...\")\n",
    "    \n",
    "    # Calculate averages by brand and country\n",
    "    brand_avgs = df_train.groupby('brand').agg({\n",
    "        'meaning': 'mean',\n",
    "        'difference': 'mean',\n",
    "        'salience': 'mean',\n",
    "        'premium': 'mean'\n",
    "    })\n",
    "    \n",
    "    country_avgs = df_train.groupby('country').agg({\n",
    "        'meaning': 'mean',\n",
    "        'difference': 'mean',\n",
    "        'salience': 'mean',\n",
    "        'premium': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Global averages (fallback)\n",
    "    global_avgs = {\n",
    "        'meaning': df_train['meaning'].mean(),\n",
    "        'difference': df_train['difference'].mean(),\n",
    "        'salience': df_train['salience'].mean(),\n",
    "        'premium': df_train['premium'].mean()\n",
    "    }\n",
    "    \n",
    "    # Fill in metrics for each test row\n",
    "    metrics = ['meaning', 'difference', 'salience', 'premium']\n",
    "    for idx, row in df_test.iterrows():\n",
    "        brand, country = row['brand'], row['country']\n",
    "        \n",
    "        # Try brand average first\n",
    "        if brand in brand_avgs.index:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = brand_avgs.loc[brand, metric]\n",
    "        \n",
    "        # Then try country average\n",
    "        elif country in country_avgs.index:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = country_avgs.loc[country, metric]\n",
    "        \n",
    "        # Fallback to global average\n",
    "        else:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = global_avgs[metric]\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "# Apply estimation to get test metrics\n",
    "df_test = estimate_brand_metrics()\n",
    "print(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed2886df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>country</th>\n",
       "      <th>brand</th>\n",
       "      <th>predicted_power</th>\n",
       "      <th>quarter_num</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>is_test</th>\n",
       "      <th>meaning</th>\n",
       "      <th>difference</th>\n",
       "      <th>salience</th>\n",
       "      <th>premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>a19bbfeafb</td>\n",
       "      <td>cd46a210c6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20243</td>\n",
       "      <td>True</td>\n",
       "      <td>140.885669</td>\n",
       "      <td>113.861601</td>\n",
       "      <td>160.464473</td>\n",
       "      <td>1.155262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>a19bbfeafb</td>\n",
       "      <td>b6a118bf97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20243</td>\n",
       "      <td>True</td>\n",
       "      <td>124.081871</td>\n",
       "      <td>104.935099</td>\n",
       "      <td>120.073537</td>\n",
       "      <td>1.054426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>a19bbfeafb</td>\n",
       "      <td>53a67488ad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20243</td>\n",
       "      <td>True</td>\n",
       "      <td>86.743503</td>\n",
       "      <td>75.443914</td>\n",
       "      <td>79.131779</td>\n",
       "      <td>0.901318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>a19bbfeafb</td>\n",
       "      <td>a0bc54a71d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20243</td>\n",
       "      <td>True</td>\n",
       "      <td>116.876435</td>\n",
       "      <td>119.421693</td>\n",
       "      <td>81.785540</td>\n",
       "      <td>1.128386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>a19bbfeafb</td>\n",
       "      <td>85498197e2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20243</td>\n",
       "      <td>True</td>\n",
       "      <td>149.631097</td>\n",
       "      <td>157.905315</td>\n",
       "      <td>125.040083</td>\n",
       "      <td>1.290739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year quarter     country       brand  predicted_power  quarter_num  \\\n",
       "0  2024    Qtr3  a19bbfeafb  cd46a210c6              NaN            3   \n",
       "1  2024    Qtr3  a19bbfeafb  b6a118bf97              NaN            3   \n",
       "2  2024    Qtr3  a19bbfeafb  53a67488ad              NaN            3   \n",
       "3  2024    Qtr3  a19bbfeafb  a0bc54a71d              NaN            3   \n",
       "4  2024    Qtr3  a19bbfeafb  85498197e2              NaN            3   \n",
       "\n",
       "   time_idx  is_test     meaning  difference    salience   premium  \n",
       "0     20243     True  140.885669  113.861601  160.464473  1.155262  \n",
       "1     20243     True  124.081871  104.935099  120.073537  1.054426  \n",
       "2     20243     True   86.743503   75.443914   79.131779  0.901318  \n",
       "3     20243     True  116.876435  119.421693   81.785540  1.128386  \n",
       "4     20243     True  149.631097  157.905315  125.040083  1.290739  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d99684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>country</th>\n",
       "      <th>brand</th>\n",
       "      <th>meaning</th>\n",
       "      <th>difference</th>\n",
       "      <th>salience</th>\n",
       "      <th>power</th>\n",
       "      <th>premium</th>\n",
       "      <th>quarter_num</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>Qtr1</td>\n",
       "      <td>653b4e6d12</td>\n",
       "      <td>de903bdf13</td>\n",
       "      <td>130.254295</td>\n",
       "      <td>105.026180</td>\n",
       "      <td>95.584143</td>\n",
       "      <td>3.075272</td>\n",
       "      <td>1.144869</td>\n",
       "      <td>1</td>\n",
       "      <td>20221</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Qtr2</td>\n",
       "      <td>653b4e6d12</td>\n",
       "      <td>de903bdf13</td>\n",
       "      <td>127.584560</td>\n",
       "      <td>103.211433</td>\n",
       "      <td>97.783428</td>\n",
       "      <td>3.247745</td>\n",
       "      <td>1.135222</td>\n",
       "      <td>2</td>\n",
       "      <td>20222</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Qtr3</td>\n",
       "      <td>653b4e6d12</td>\n",
       "      <td>de903bdf13</td>\n",
       "      <td>130.226966</td>\n",
       "      <td>103.829670</td>\n",
       "      <td>95.621699</td>\n",
       "      <td>3.159509</td>\n",
       "      <td>1.154649</td>\n",
       "      <td>3</td>\n",
       "      <td>20223</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>Qtr4</td>\n",
       "      <td>653b4e6d12</td>\n",
       "      <td>de903bdf13</td>\n",
       "      <td>134.213403</td>\n",
       "      <td>103.584346</td>\n",
       "      <td>97.724214</td>\n",
       "      <td>3.428511</td>\n",
       "      <td>1.172568</td>\n",
       "      <td>4</td>\n",
       "      <td>20224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Qtr1</td>\n",
       "      <td>653b4e6d12</td>\n",
       "      <td>de903bdf13</td>\n",
       "      <td>130.779928</td>\n",
       "      <td>103.717619</td>\n",
       "      <td>101.117547</td>\n",
       "      <td>3.590078</td>\n",
       "      <td>1.164770</td>\n",
       "      <td>1</td>\n",
       "      <td>20231</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year quarter     country       brand     meaning  difference    salience  \\\n",
       "0  2022    Qtr1  653b4e6d12  de903bdf13  130.254295  105.026180   95.584143   \n",
       "1  2022    Qtr2  653b4e6d12  de903bdf13  127.584560  103.211433   97.783428   \n",
       "2  2022    Qtr3  653b4e6d12  de903bdf13  130.226966  103.829670   95.621699   \n",
       "3  2022    Qtr4  653b4e6d12  de903bdf13  134.213403  103.584346   97.724214   \n",
       "4  2023    Qtr1  653b4e6d12  de903bdf13  130.779928  103.717619  101.117547   \n",
       "\n",
       "      power   premium  quarter_num  time_idx  is_test  \n",
       "0  3.075272  1.144869            1     20221    False  \n",
       "1  3.247745  1.135222            2     20222    False  \n",
       "2  3.159509  1.154649            3     20223    False  \n",
       "3  3.428511  1.172568            4     20224    False  \n",
       "4  3.590078  1.164770            1     20231    False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dc0b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr_bounds(df: pd.DataFrame, columns: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates the IQR bounds (upper and lower) for specified columns in the DataFrame.\n",
    "    :param df: DataFrame to calculate IQR bounds for\n",
    "    :param columns: List of column names to calculate bounds for\n",
    "    :return: Dictionary with column names as keys and (lower_bound, upper_bound) as values\n",
    "    \"\"\"\n",
    "    # Check if all specified columns are present in the DataFrame\n",
    "    missing_columns = [col for col in columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(\n",
    "            f\"The following columns are not in the DataFrame: {missing_columns}\"\n",
    "        )\n",
    "\n",
    "    bounds = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        bounds[col] = (lower_bound, upper_bound)\n",
    "\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def cap_outliers(df: pd.DataFrame, bounds: dict) -> pd.DataFrame:\n",
    "    df_capped = df.copy()\n",
    "    for col, (low, high) in bounds.items():\n",
    "        df_capped[col] = df_capped[col].clip(lower=low, upper=high)\n",
    "    return df_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ed497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for prediction model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- power\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     27\u001b[0m train_data[numeric_cols] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(train_data[numeric_cols])\n\u001b[1;32m---> 28\u001b[0m df_test[numeric_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeaning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifference\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremium\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Encode categorical features\u001b[39;00m\n\u001b[0;32m     31\u001b[0m label_encoders \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\40108679\\AppData\\Local\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\40108679\\AppData\\Local\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\40108679\\AppData\\Local\\miniconda3\\lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\40108679\\AppData\\Local\\miniconda3\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- power\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare data for model training\n",
    "print(\"Preparing data for prediction model...\")\n",
    "\n",
    "# Only use train data with non-null 'power'\n",
    "train_data = df_train[df_train['power'].notnull()].copy()\n",
    "\n",
    "# apply outlier capping\n",
    "numeric_cols = ['meaning', 'difference', 'salience', 'premium', 'power']\n",
    "iqr_bounds = calculate_iqr_bounds(train_data, numeric_cols)\n",
    "train_data = cap_outliers(train_data, iqr_bounds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in ['country', 'brand']:\n",
    "    le = LabelEncoder()\n",
    "    train_data[f'{col}_encoded'] = le.fit_transform(train_data[col])\n",
    "    df_test[f'{col}_encoded'] = le.transform(df_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Select features and target\n",
    "features = ['year', 'quarter_num', 'country_encoded', 'brand_encoded', \n",
    "            'meaning', 'difference', 'salience', 'premium']\n",
    "target = 'power'\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data[features], \n",
    "    train_data[target], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest model\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_pred = model.predict(X_val)\n",
    "val_score = r2_score(y_val, val_pred)\n",
    "print(f\"Model RÂ² score on validation data: {val_score:.4f}\")\n",
    "\n",
    "# Predict on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "df_test['power'] = model.predict(df_test[features])\n",
    "\n",
    "# Apply minimum value constraint (power cannot be negative)\n",
    "df_test['power'] = df_test['power'].clip(lower=0)\n",
    "\n",
    "# Show predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(df_test[['year', 'quarter', 'country', 'brand', 'power']].head(10))\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission = df_test[['year', 'quarter', 'country', 'brand', 'power']]\n",
    "submission.to_csv('brand_power_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'brand_power_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2eb51f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Power Prediction Score (PPS)...\n",
      "RMSE: 0.3443\n",
      "Standard Deviation of Power: 1.6648\n",
      "RMSE Skill Score: 0.7932\n",
      "Trend Hits: 162 out of 214\n",
      "Trend Hit Rate: 0.7570\n",
      "Power Prediction Score (PPS): 0.7751\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to calculate evaluation metrics for your predictions\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_pps():\n",
    "    print(\"Calculating Power Prediction Score (PPS)...\")\n",
    "    \n",
    "    # We need to compare against validation data since we don't have true values for test set\n",
    "    # Use the validation split you already created\n",
    "    y_true = y_val\n",
    "    y_pred = val_pred\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Calculate standard deviation of target variable\n",
    "    sigma_y = np.std(y_true)\n",
    "    \n",
    "    # Calculate RMSE Skill Score\n",
    "    rmse_skill = max(0, min(1, 1 - rmse/sigma_y))\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"Standard Deviation of Power: {sigma_y:.4f}\")\n",
    "    print(f\"RMSE Skill Score: {rmse_skill:.4f}\")\n",
    "    \n",
    "    # Calculate Trend Hit Rate\n",
    "    # Group data by brand and country\n",
    "    validation_data = X_val.copy()\n",
    "    validation_data['power_true'] = y_true\n",
    "    validation_data['power_pred'] = y_pred\n",
    "    \n",
    "    # Add time_idx back to validation data for sorting\n",
    "    # Create time index from year and quarter_num which are already in X_val\n",
    "    validation_data['time_idx'] = validation_data['year']*10 + validation_data['quarter_num']\n",
    "    \n",
    "    # Add brand and country back to validation data for grouping\n",
    "    validation_data['brand'] = train_data.loc[validation_data.index, 'brand'].values\n",
    "    validation_data['country'] = train_data.loc[validation_data.index, 'country'].values\n",
    "    \n",
    "    # Calculate trend hit rate across brand-country pairs\n",
    "    trend_hits = 0\n",
    "    total_cases = 0\n",
    "    \n",
    "    # Group by brand and country\n",
    "    for (brand, country), group in validation_data.groupby(['brand', 'country']):\n",
    "        # Sort by time\n",
    "        group = group.sort_values('time_idx')\n",
    "        \n",
    "        # Need at least 2 points to calculate trend\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate deltas for true and predicted values\n",
    "        true_deltas = np.sign(np.diff(group['power_true']))\n",
    "        pred_deltas = np.sign(np.diff(group['power_pred']))\n",
    "        \n",
    "        # Compare trends (direction of change)\n",
    "        hits = (true_deltas == pred_deltas).sum()\n",
    "        \n",
    "        trend_hits += hits\n",
    "        total_cases += len(true_deltas)\n",
    "    \n",
    "    # Calculate trend hit rate\n",
    "    trend_hit_rate = trend_hits / total_cases if total_cases > 0 else 0\n",
    "    print(f\"Trend Hits: {trend_hits} out of {total_cases}\")\n",
    "    print(f\"Trend Hit Rate: {trend_hit_rate:.4f}\")\n",
    "    \n",
    "    # Calculate final PPS\n",
    "    pps = 0.5 * rmse_skill + 0.5 * trend_hit_rate\n",
    "    print(f\"Power Prediction Score (PPS): {pps:.4f}\")\n",
    "    \n",
    "    return pps, rmse_skill, trend_hit_rate\n",
    "\n",
    "# Calculate PPS\n",
    "pps, rmse_skill, trend_hit_rate = calculate_pps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dad04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
