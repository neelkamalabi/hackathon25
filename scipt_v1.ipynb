{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load data\n",
    "train_path = r'C:\\Users\\40108679\\OneDrive - Anheuser-Busch InBev\\Desktop\\Hackathon-2025\\lte_participants_data\\BG_Data_Hackathon_Train_masked.csv'\n",
    "test_path = r'C:\\Users\\40108679\\OneDrive - Anheuser-Busch InBev\\Desktop\\Hackathon-2025\\lte_participants_data\\BG_Data_Hackathon_Test_Predict_masked.csv'\n",
    "\n",
    "print(\"Loading data files...\")\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Standardize column names\n",
    "if 'Year' in df_test.columns:\n",
    "    df_test = df_test.rename(columns={'Year': 'year', 'Quarter': 'quarter', 'Country': 'country', \n",
    "                                     'Brand': 'brand', 'Predicted Power': 'predicted_power'})\n",
    "\n",
    "# Create quarter numeric values for time series ordering\n",
    "df_train['quarter_num'] = df_train['quarter'].str.replace('Qtr', '').astype(int)\n",
    "df_test['quarter_num'] = df_test['quarter'].str.replace('Qtr', '').astype(int)\n",
    "\n",
    "# Create time index for easier analysis\n",
    "df_train['time_idx'] = df_train['year']*10 + df_train['quarter_num']\n",
    "df_test['time_idx'] = df_test['year']*10 + df_test['quarter_num']\n",
    "\n",
    "# Create a combined DataFrame for easier sorting and mapping\n",
    "df_test['is_test'] = True\n",
    "df_train['is_test'] = False\n",
    "combined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "combined = combined.sort_values(['brand', 'country', 'year', 'quarter_num'])\n",
    "\n",
    "print(f\"Training data: {len(df_train)} rows\")\n",
    "print(f\"Test data: {len(df_test)} rows\")\n",
    "\n",
    "# Estimate brand metrics for test data using brand and country averages\n",
    "def estimate_brand_metrics():\n",
    "    print(\"Estimating brand metrics for test data...\")\n",
    "    \n",
    "    # Calculate averages by brand and country\n",
    "    brand_avgs = df_train.groupby('brand').agg({\n",
    "        'meaning': 'mean',\n",
    "        'difference': 'mean',\n",
    "        'salience': 'mean',\n",
    "        'premium': 'mean'\n",
    "    })\n",
    "    \n",
    "    country_avgs = df_train.groupby('country').agg({\n",
    "        'meaning': 'mean',\n",
    "        'difference': 'mean',\n",
    "        'salience': 'mean',\n",
    "        'premium': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Global averages (fallback)\n",
    "    global_avgs = {\n",
    "        'meaning': df_train['meaning'].mean(),\n",
    "        'difference': df_train['difference'].mean(),\n",
    "        'salience': df_train['salience'].mean(),\n",
    "        'premium': df_train['premium'].mean()\n",
    "    }\n",
    "    \n",
    "    # Fill in metrics for each test row\n",
    "    metrics = ['meaning', 'difference', 'salience', 'premium']\n",
    "    for idx, row in df_test.iterrows():\n",
    "        brand, country = row['brand'], row['country']\n",
    "        \n",
    "        # Try brand average first\n",
    "        if brand in brand_avgs.index:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = brand_avgs.loc[brand, metric]\n",
    "        \n",
    "        # Then try country average\n",
    "        elif country in country_avgs.index:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = country_avgs.loc[country, metric]\n",
    "        \n",
    "        # Fallback to global average\n",
    "        else:\n",
    "            for metric in metrics:\n",
    "                df_test.loc[idx, metric] = global_avgs[metric]\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "# Apply estimation to get test metrics\n",
    "df_test = estimate_brand_metrics()\n",
    "print(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr_bounds(df: pd.DataFrame, columns: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates the IQR bounds (upper and lower) for specified columns in the DataFrame.\n",
    "    :param df: DataFrame to calculate IQR bounds for\n",
    "    :param columns: List of column names to calculate bounds for\n",
    "    :return: Dictionary with column names as keys and (lower_bound, upper_bound) as values\n",
    "    \"\"\"\n",
    "    # Check if all specified columns are present in the DataFrame\n",
    "    missing_columns = [col for col in columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(\n",
    "            f\"The following columns are not in the DataFrame: {missing_columns}\"\n",
    "        )\n",
    "\n",
    "    bounds = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        bounds[col] = (lower_bound, upper_bound)\n",
    "\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def cap_outliers(df: pd.DataFrame, bounds: dict) -> pd.DataFrame:\n",
    "    df_capped = df.copy()\n",
    "    for col, (low, high) in bounds.items():\n",
    "        df_capped[col] = df_capped[col].clip(lower=low, upper=high)\n",
    "    return df_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare data for model training\n",
    "print(\"Preparing data for prediction model...\")\n",
    "\n",
    "# Only use train data with non-null 'power'\n",
    "train_data = df_train[df_train['power'].notnull()].copy()\n",
    "\n",
    "# apply outlier capping\n",
    "numeric_cols = ['meaning', 'difference', 'salience', 'premium', 'power']\n",
    "iqr_bounds = calculate_iqr_bounds(train_data, numeric_cols)\n",
    "train_data = cap_outliers(train_data, iqr_bounds)\n",
    "\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in ['country', 'brand']:\n",
    "    le = LabelEncoder()\n",
    "    train_data[f'{col}_encoded'] = le.fit_transform(train_data[col])\n",
    "    df_test[f'{col}_encoded'] = le.transform(df_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Select features and target\n",
    "features = ['year', 'quarter_num', 'country_encoded', 'brand_encoded', \n",
    "            'meaning', 'difference', 'salience', 'premium']\n",
    "target = 'power'\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data[features], \n",
    "    train_data[target], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest model\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_pred = model.predict(X_val)\n",
    "val_score = r2_score(y_val, val_pred)\n",
    "print(f\"Model RÂ² score on validation data: {val_score:.4f}\")\n",
    "\n",
    "# Predict on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "df_test['power'] = model.predict(df_test[features])\n",
    "\n",
    "# Apply minimum value constraint (power cannot be negative)\n",
    "df_test['power'] = df_test['power'].clip(lower=0)\n",
    "\n",
    "# Show predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(df_test[['year', 'quarter', 'country', 'brand', 'power']].head(10))\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission = df_test[['year', 'quarter', 'country', 'brand', 'power']]\n",
    "submission.to_csv('brand_power_predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'brand_power_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this cell to calculate evaluation metrics for your predictions\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_pps():\n",
    "    print(\"Calculating Power Prediction Score (PPS)...\")\n",
    "    \n",
    "    # We need to compare against validation data since we don't have true values for test set\n",
    "    # Use the validation split you already created\n",
    "    y_true = y_val\n",
    "    y_pred = val_pred\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Calculate standard deviation of target variable\n",
    "    sigma_y = np.std(y_true)\n",
    "    \n",
    "    # Calculate RMSE Skill Score\n",
    "    rmse_skill = max(0, min(1, 1 - rmse/sigma_y))\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"Standard Deviation of Power: {sigma_y:.4f}\")\n",
    "    print(f\"RMSE Skill Score: {rmse_skill:.4f}\")\n",
    "    \n",
    "    # Calculate Trend Hit Rate\n",
    "    # Group data by brand and country\n",
    "    validation_data = X_val.copy()\n",
    "    validation_data['power_true'] = y_true\n",
    "    validation_data['power_pred'] = y_pred\n",
    "    \n",
    "    # Add time_idx back to validation data for sorting\n",
    "    # Create time index from year and quarter_num which are already in X_val\n",
    "    validation_data['time_idx'] = validation_data['year']*10 + validation_data['quarter_num']\n",
    "    \n",
    "    # Add brand and country back to validation data for grouping\n",
    "    validation_data['brand'] = train_data.loc[validation_data.index, 'brand'].values\n",
    "    validation_data['country'] = train_data.loc[validation_data.index, 'country'].values\n",
    "    \n",
    "    # Calculate trend hit rate across brand-country pairs\n",
    "    trend_hits = 0\n",
    "    total_cases = 0\n",
    "    \n",
    "    # Group by brand and country\n",
    "    for (brand, country), group in validation_data.groupby(['brand', 'country']):\n",
    "        # Sort by time\n",
    "        group = group.sort_values('time_idx')\n",
    "        \n",
    "        # Need at least 2 points to calculate trend\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Calculate deltas for true and predicted values\n",
    "        true_deltas = np.sign(np.diff(group['power_true']))\n",
    "        pred_deltas = np.sign(np.diff(group['power_pred']))\n",
    "        \n",
    "        # Compare trends (direction of change)\n",
    "        hits = (true_deltas == pred_deltas).sum()\n",
    "        \n",
    "        trend_hits += hits\n",
    "        total_cases += len(true_deltas)\n",
    "    \n",
    "    # Calculate trend hit rate\n",
    "    trend_hit_rate = trend_hits / total_cases if total_cases > 0 else 0\n",
    "    print(f\"Trend Hits: {trend_hits} out of {total_cases}\")\n",
    "    print(f\"Trend Hit Rate: {trend_hit_rate:.4f}\")\n",
    "    \n",
    "    # Calculate final PPS\n",
    "    pps = 0.5 * rmse_skill + 0.5 * trend_hit_rate\n",
    "    print(f\"Power Prediction Score (PPS): {pps:.4f}\")\n",
    "    \n",
    "    return pps, rmse_skill, trend_hit_rate\n",
    "\n",
    "# Calculate PPS\n",
    "pps, rmse_skill, trend_hit_rate = calculate_pps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
